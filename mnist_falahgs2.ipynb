{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-falahgs2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falahgs/falahgs/blob/master/mnist_falahgs2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jQX6TYuebXWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "208a1c47-4ae0-4fb8-a608-d4403c12a4c0"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# Reshaping to format which CNN expects (batch, height, width, channels)\n",
        "X_train = X_train.reshape(X_train.shape[0],1,28,28)\n",
        "X_test = X_test.reshape(X_test.shape[0],1,28,28)\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train=X_train.astype('float32')\n",
        "X_test=X_test.astype('float32')\n",
        "X_train/=255\n",
        "X_test/=255\n",
        "# one hot encode\n",
        "number_of_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
        "y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(1,28,28), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(number_of_classes, activation='softmax'))\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "# Save the model\n",
        "model.save(\"/content/drive/My Drive/model/mnist-model2019.h5\") \n",
        "# Final evaluation of the model\n",
        "metrics = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Metrics(Test loss & Test Accuracy): \")\n",
        "print(metrics)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 264s 4ms/step - loss: 0.2891 - acc: 0.9159 - val_loss: 0.0641 - val_acc: 0.9790\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 248s 4ms/step - loss: 0.0768 - acc: 0.9767 - val_loss: 0.0535 - val_acc: 0.9828\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 248s 4ms/step - loss: 0.0565 - acc: 0.9830 - val_loss: 0.0357 - val_acc: 0.9875\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 250s 4ms/step - loss: 0.0478 - acc: 0.9851 - val_loss: 0.0302 - val_acc: 0.9897\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 247s 4ms/step - loss: 0.0393 - acc: 0.9881 - val_loss: 0.0315 - val_acc: 0.9894\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 246s 4ms/step - loss: 0.0341 - acc: 0.9891 - val_loss: 0.0224 - val_acc: 0.9925\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 246s 4ms/step - loss: 0.0301 - acc: 0.9907 - val_loss: 0.0237 - val_acc: 0.9922\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 247s 4ms/step - loss: 0.0261 - acc: 0.9916 - val_loss: 0.0259 - val_acc: 0.9913\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 250s 4ms/step - loss: 0.0230 - acc: 0.9923 - val_loss: 0.0231 - val_acc: 0.9929\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 246s 4ms/step - loss: 0.0221 - acc: 0.9929 - val_loss: 0.0217 - val_acc: 0.9929\n",
            "Metrics(Test loss & Test Accuracy): \n",
            "[0.021658973167283692, 0.9929]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}